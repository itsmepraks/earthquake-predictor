# Earthquake Predictor Streamlit App

## Project Overview

This project aims to build a scalable and maintainable Streamlit application for short-term earthquake risk prediction in Nepal. We will leverage historical seismic datasets (USGS Himalayan records, 2015 Gorkha event, NASA Earthdata, and Kaggle sources) to train probabilistic and categorical classification models (using scikit-learn) and present results through an interactive web interface.

## Plan of Action

### Phase 1: Project Setup & Environment
1. Initialize project structure:
   - `data/` (raw & processed datasets)
   - `src/` (data loading, preprocessing, modeling modules)
   - `app/` (Streamlit application code)
2. Create and activate Python virtual environment (venv).
3. Add `requirements.txt` with core dependencies (streamlit, scikit-learn, pandas, numpy, geopandas, folium).
4. Initialize `todo.md` to track tasks and progress.

### Phase 2: Data Acquisition & Preprocessing
1. Identify and script downloads for:
   - USGS Himalayan earthquake data
   - 2015 Gorkha aftershock dataset
   - NASA terrain elevation data
   - Supplementary Kaggle datasets
2. Standardize schema across sources (columns, units, datetime formats).
3. Handle missing values, outliers, and merge datasets.
4. Engineer features: magnitude thresholds, geographical zoning (grid or polygons), terrain attributes.

### Phase 3: Modeling Pipeline
1. Define target variables:
   - Probability of an event exceeding a magnitude threshold within a region.
   - Categorical risk levels (Low, Medium, High).
2. Implement data splitting and cross-validation framework.
3. Train baseline models with scikit-learn:
   - Logistic Regression (probabilistic output)
   - Map probability thresholds to categorical risk.
4. Evaluate using ROC AUC, accuracy, confusion matrices.

### Phase 4: Model Evaluation & Tuning
1. Analyze performance metrics and feature importance.
2. Refine thresholds and class bins for risk levels.
3. Document insights in `whitepaper.md` and update `proposal.md` if needed.

### Phase 5: Streamlit Application Development
1. Design UI layout:
   - Sidebar: dataset selection, magnitude threshold slider, model options.
   - Main view: interactive map (Folium or Streamlit-native) showing risk overlays and historical points.
   - Charts: probability distributions, feature importance bar plot.
2. Integrate preprocessing and model inference modules from `src/`.
3. Add caching for performance (Streamlit `@st.cache_data`).

### Phase 6: Documentation & Version Control
1. Maintain `todo.md` with completed and pending tasks at each step.
2. Update `whitepaper.md` with methodology and results.

### Phase 7: Iterative Improvements
Create a new v2.md file for the next phase of the project with the following details:
1. Introduce advanced models (Random Forest, SVM).
2. Hyperparameter tuning (GridSearchCV).
3. Enhance visualizations (heatmaps, time-series animations).
4. Deploy via Streamlit Cloud or other hosting.

---

