# Earthquake Predictor - V2 Plan

This document outlines the plan for the second major phase of the Earthquake Predictor project, focusing on advanced modeling, feature enhancement, and finalization according to the goals in `proposal.md`.

## Plan of Action

### Phase 7: Advanced Modeling & Hyperparameter Tuning

1.  **Implement Random Forest:**
    *   Train a `RandomForestClassifier` model on the processed data (`data/processed/buildings_features_earthquakes.csv`).
    *   Utilize appropriate preprocessing (likely `OrdinalEncoder` as used for LightGBM, or potentially `OneHotEncoder` if memory allows).
    *   Evaluate performance using Accuracy, ROC AUC (OvR Macro), F1-score (Weighted/Macro), and Confusion Matrix.
    *   Extract and analyze feature importance scores (`feature_importances_`).
2.  **Implement Support Vector Machine (SVM):**
    *   Train an `SVC` (potentially with a linear kernel or using `LinearSVC` for scalability) on the scaled data.
    *   Address potential scalability issues (e.g., use a subset of data for initial tests if needed, focus on `LinearSVC`).
    *   Evaluate performance similarly to Random Forest.
    *   Analyze feature importance if using `LinearSVC` (via `coef_`).
3.  **Hyperparameter Tuning:**
    *   Select the top 1-2 performing models (candidates: LightGBM, Random Forest, possibly SVM if performance is competitive).
    *   Use `GridSearchCV` or `RandomizedSearchCV` (preferable for larger search spaces or faster iteration) to optimize key hyperparameters.
        *   *LightGBM:* `num_leaves`, `max_depth`, `learning_rate`, `n_estimators`, `reg_alpha`, `reg_lambda`.
        *   *Random Forest:* `n_estimators`, `max_depth`, `min_samples_split`, `min_samples_leaf`, `max_features`.
        *   *SVM:* `C`, `kernel`, `gamma` (if using non-linear kernel).
    *   Retrain the best models with optimized hyperparameters.
4.  **Model Comparison & Selection:**
    *   Create a comparative summary table (or visualization) showing performance metrics (Accuracy, AUC, F1, Precision/Recall per class) and training times for all models (Logistic Regression, LightGBM, Random Forest, SVM, tuned versions).
    *   Select the final model(s) to be used in the Streamlit application based on performance and potentially inference speed.
    *   Document the final model selection rationale in `whitepaper.md`.

### Phase 8: Feature & Visualization Enhancements

1.  **Revisit Feature Engineering (Terrain Data):**
    *   **Data Acquisition:** Attempt to locate and download suitable SRTM (or similar) elevation datasets covering Nepal.
    *   **Processing:** Process the terrain data (e.g., create slope and aspect layers from elevation).
    *   **Integration:** Investigate methods to link terrain data to building data. Potential strategies:
        *   Aggregate terrain features (mean/median elevation, slope) per `geo_level_id` using shapefile boundaries if a reliable PCODE join can be established.
        *   If direct join fails, consider using the provided `geo_level_id`s as proxies for zones and calculating zonal statistics if boundary definitions can be inferred or approximated.
    *   **Retraining:** If terrain features are successfully integrated, retrain the final selected model(s) and evaluate the impact on performance.
2.  **Revisit Map Visualization:**
    *   **Geo ID Mapping:** Perform a focused investigation to link `geo_level_id` (especially `geo_level_2_id` or `geo_level_3_id`) to the PCODEs used in the `npl_adm_nd_20240314_ab_shp` shapefiles. Search for official crosswalk tables or metadata.
    *   **Implementation:**
        *   *If Mapping Successful:* Implement a choropleth map in the Streamlit app (using Folium or `st.map` with GeoPandas) showing predicted average damage risk aggregated to the corresponding administrative level (e.g., ADM2).
        *   *If Mapping Fails:* Implement a choropleth map aggregated by the highest feasible `geo_level_id` (e.g., `geo_level_1_id` or `geo_level_2_id` average risk), clearly stating the limitation.
    *   **Integration:** Add the map visualization to the main panel of the Streamlit app.
3.  **Enhance Streamlit Application:**
    *   Update the model selection dropdown to include the final chosen model(s) (e.g., Tuned LightGBM, Tuned Random Forest).
    *   Ensure the feature importance chart correctly displays importances for the selected model type.
    *   Add a section to display the comparative performance metrics of the available models.
    *   Integrate the map visualization developed in the previous step.
    *   Review and refine the UI/UX, ensuring clarity and ease of use with the added features.

### Phase 9: Final Documentation & Wrap-up

1.  **Update Documentation:**
    *   **`whitepaper.md`:** Add detailed sections covering:
        *   Random Forest and SVM implementation and results.
        *   Hyperparameter tuning process and outcomes.
        *   Final model comparison and selection rationale.
        *   Results of terrain feature integration (if successful).
        *   Description and interpretation of the final map visualization.
        *   Updated Streamlit app features.
        *   A concluding summary of achievements, limitations, and potential future work.
    *   **`data/data_dictionary.md`:** Add entries for any new terrain features if they were successfully added to the processed dataset.
    *   **`todo.md`:** Mark all Phase 7, 8, and 9 tasks as complete.
    *   **`README.md` (Create/Update):** Ensure a top-level `README.md` exists that explains the project, how to set it up, and how to run the Streamlit application.
2.  **Final Code Review:**
    *   Perform a thorough review of the code in `src/` and `app/`.
    *   Ensure code is well-commented, follows consistent style (e.g., PEP 8), and removes any unused or debugging code.
    *   Verify that necessary requirements are listed in `requirements.txt`.
3.  **Project Archive/Handover:**
    *   Ensure all relevant data, models, code, and documentation are committed to version control.
    *   (Optional) Consider adding instructions for deploying the Streamlit app. 